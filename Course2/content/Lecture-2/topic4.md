# Глава 4: Поиск и Хеширование

В предыдущих главах мы научились сортировать данные. Теперь разберем задачу поиска. Допустим, у нас есть база данных из $N$ записей, и нам нужно быстро найти запись по ключу (например, найти студента по ID).

## 4.1 Бинарный поиск (Binary Search)

Если массив **уже отсортирован**, нам не нужно просматривать все элементы подряд (линейный поиск, $O(N)$). Мы можем использовать метод деления пополам.

Алгоритм:
1.  Смотрим в середину массива.
2.  Если число в середине больше искомого, ищем в левой половине.
3.  Если меньше — в правой.
4.  Повторяем, пока интервал поиска не схлопнется.

Каждый шаг уменьшает область поиска в 2 раза. Количество шагов равно количеству раз, которое нужно разделить $N$ на 2, чтобы получить 1. Это логарифм по основанию 2.
Сложность: $T(N) = O(\log N)$.

Пример: Среди 1 000 000 элементов бинарный поиск найдет нужный максимум за 20 операций ($2^{20} \approx 10^6$). Линейный поиск в среднем сделает 500 000 операций. Разница колоссальна.

-----

## 4.2 Хеш-таблицы (Hash Tables)

Что если мы хотим искать за $O(1)$, то есть мгновенно, и не хотим постоянно поддерживать массив отсортированным? Для этого используются хеш-таблицы (в Python это `dict`, в C++ `std::unordered_map`).

Идея: Индекс в массиве вычисляется на основе значения самого элемента с помощью специальной **хеш-функции**.
$$\text{index} = \text{hash}(key) \pmod{\text{Size}}$$

### Коллизии
Поскольку размер массива ограничен, а количество возможных ключей бесконечно, неизбежна ситуация, когда для двух разных ключей хеш-функция выдаст одинаковый индекс. Это называется **коллизией**.
$$\text{hash}(\text{"apple"}) = \text{hash}(\text{"orange"})$$

Существует два основных метода разрешения коллизий:

1.  **Метод цепочек (Chaining):**
    Каждая ячейка массива хранит не элемент, а указатель на связный список. Все элементы с одинаковым хешем просто добавляются в этот список.
    * Если коллизий мало, длина списков мала, и поиск работает за $O(1)$.
    * В худшем случае (все ключи попали в одну ячейку) хеш-таблица вырождается в связный список с поиском $O(N)$.

2.  **Открытая адресация (Open Addressing):**
    Если ячейка занята, мы ищем следующую свободную ячейку по определенному правилу (например, просто берем следующую: `index + 1`, `index + 2` и т.д.).

### Требования к хеш-функции
Хорошая хеш-функция должна:
* Быстро вычисляться.
* Равномерно распределять ключи по таблице.
* Быть детерминированной (для одного ключа всегда возвращать один и тот же результат).

Пример простой полиномиальной хеш-функции для строк:
$$H(S) = (S[0] \cdot P^0 + S[1] \cdot P^1 + S[2] \cdot P^2 + \dots) \pmod M$$
Где $P$ — простое число (обычно 31 или 53), а $M$ — размер хеш-таблицы.

-----

## 4.3 Двоичные деревья поиска (BST)

Еще одна структура для эффективного поиска — **Binary Search Tree**.
Это дерево, где для каждого узла выполняется правило:
* Все элементы в левом поддереве **меньше** текущего.
* Все элементы в правом поддереве **больше** текущего.

Поиск в таком дереве напоминает бинарный поиск в массиве. Если дерево сбалансировано (его высота близка к $\log N$), операции вставки, удаления и поиска занимают $O(\log N)$.
Однако, если добавлять уже отсортированные числа (1, 2, 3, 4, 5), дерево выродится в «палку» (связный список), и сложность упадет до $O(N)$. Для решения этой проблемы используются самобалансирующиеся деревья (AVL, Red-Black Tree), которые мы рассмотрим в продвинутых курсах.